import { _ as _export_sfc, c as createElementBlock, o as openBlock, ai as createStaticVNode } from "./chunks/framework.CZ94uQXh.js";
const __pageData = JSON.parse('{"title":"Observability with Logfire.jl","description":"","frontmatter":{},"headers":[],"relativePath":"extra_tools/observability_logfire.md","filePath":"extra_tools/observability_logfire.md","lastUpdated":null}');
const _sfc_main = { name: "extra_tools/observability_logfire.md" };
function _sfc_render(_ctx, _cache, $props, $setup, $data, $options) {
  return openBlock(), createElementBlock("div", null, [..._cache[0] || (_cache[0] = [
    createStaticVNode('<h1 id="Observability-with-Logfire.jl" tabindex="-1">Observability with Logfire.jl <a class="header-anchor" href="#Observability-with-Logfire.jl" aria-label="Permalink to &quot;Observability with Logfire.jl {#Observability-with-Logfire.jl}&quot;">​</a></h1><p><a href="https://github.com/svilupp/Logfire.jl" target="_blank" rel="noreferrer">Logfire.jl</a> provides OpenTelemetry-based observability for your LLM applications built with PromptingTools.jl. It automatically traces all your AI calls with detailed information about tokens, costs, messages, and latency.</p><h2 id="Why-Logfire.jl?" tabindex="-1">Why Logfire.jl? <a class="header-anchor" href="#Why-Logfire.jl?" aria-label="Permalink to &quot;Why Logfire.jl? {#Why-Logfire.jl?}&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:right;">Benefit</th><th style="text-align:right;">Description</th></tr></thead><tbody><tr><td style="text-align:right;"><strong>Automatic Tracing</strong></td><td style="text-align:right;">All <code>ai*</code> function calls are traced with zero code changes</td></tr><tr><td style="text-align:right;"><strong>Full Visibility</strong></td><td style="text-align:right;">Token usage, costs, latency, messages, and errors captured</td></tr><tr><td style="text-align:right;"><strong>Flexible Backends</strong></td><td style="text-align:right;">Use Logfire cloud, Jaeger, Langfuse, or any OTLP-compatible backend</td></tr><tr><td style="text-align:right;"><strong>Cross-Language</strong></td><td style="text-align:right;">Same observability infrastructure works with Python and TypeScript</td></tr><tr><td style="text-align:right;"><strong>Generous Free Tier</strong></td><td style="text-align:right;">Hundreds of thousands of traced conversations/month on Logfire cloud</td></tr></tbody></table><h2 id="Cross-Language-Ecosystem" tabindex="-1">Cross-Language Ecosystem <a class="header-anchor" href="#Cross-Language-Ecosystem" aria-label="Permalink to &quot;Cross-Language Ecosystem {#Cross-Language-Ecosystem}&quot;">​</a></h2><p>Logfire is available across multiple languages, enabling teams to share observability infrastructure:</p><table tabindex="0"><thead><tr><th style="text-align:right;">Language</th><th style="text-align:right;">Package</th><th style="text-align:right;">Installation</th></tr></thead><tbody><tr><td style="text-align:right;"><strong>Julia</strong></td><td style="text-align:right;"><a href="https://github.com/svilupp/Logfire.jl" target="_blank" rel="noreferrer">Logfire.jl</a></td><td style="text-align:right;"><code>Pkg.add(&quot;Logfire&quot;)</code></td></tr><tr><td style="text-align:right;"><strong>Python</strong></td><td style="text-align:right;"><a href="https://docs.pydantic.dev/logfire/" target="_blank" rel="noreferrer">logfire</a></td><td style="text-align:right;"><code>pip install logfire</code></td></tr></tbody></table><p>All traces flow to the same <a href="https://pydantic.dev/logfire" target="_blank" rel="noreferrer">Pydantic Logfire</a> dashboard, giving you unified visibility across your entire stack!</p><h2 id="Installation" tabindex="-1">Installation <a class="header-anchor" href="#Installation" aria-label="Permalink to &quot;Installation {#Installation}&quot;">​</a></h2><p>Logfire.jl is a separate package that provides a PromptingTools extension. Install it along with DotEnv for loading secrets:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Pkg</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Pkg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">add</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Logfire&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;DotEnv&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre></div><p>The extension is loaded automatically when both packages are present - no additional configuration needed.</p><h2 id="Quick-Start" tabindex="-1">Quick Start <a class="header-anchor" href="#Quick-Start" aria-label="Permalink to &quot;Quick Start {#Quick-Start}&quot;">​</a></h2><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DotEnv</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">DotEnv</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">load!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Load LOGFIRE_TOKEN and API keys from .env file</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Logfire, PromptingTools</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. Configure Logfire (uses LOGFIRE_TOKEN env var, or pass token directly)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">configure</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(service_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;my-app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. Instrument all registered models - wraps them with tracing schema</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">instrument_promptingtools!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 3. Use PromptingTools as normal - traces are automatic!</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is 2 + 2?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt4om&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="How-It-Works" tabindex="-1">How It Works <a class="header-anchor" href="#How-It-Works" aria-label="Permalink to &quot;How It Works {#How-It-Works}&quot;">​</a></h2><p>The integration works by wrapping registered models in a Logfire tracing schema. When you call <code>instrument_promptingtools!()</code>, Logfire modifies the model registry to route all calls through its tracing layer. This means:</p><ul><li><p>All <code>ai*</code> functions work exactly as before</p></li><li><p>No code changes needed in your existing workflows</p></li><li><p>Traces are captured automatically with rich metadata</p></li></ul><h2 id="What-Gets-Captured" tabindex="-1">What Gets Captured <a class="header-anchor" href="#What-Gets-Captured" aria-label="Permalink to &quot;What Gets Captured {#What-Gets-Captured}&quot;">​</a></h2><p>Each AI call creates a span with:</p><ul><li><p><strong>Request parameters</strong>: model, temperature, top_p, max_tokens, stop, penalties</p></li><li><p><strong>Usage metrics</strong>: input/output/total tokens, latency, cost estimates</p></li><li><p><strong>Provider metadata</strong>: model returned, status, finish_reason, response_id</p></li><li><p><strong>Conversation</strong>: full message history (roles + content)</p></li><li><p><strong>Cache &amp; streaming</strong>: flags and chunk counts</p></li><li><p><strong>Tool/function calls</strong>: count and payload</p></li><li><p><strong>Errors</strong>: exceptions with span status set to error</p></li></ul><h2 id="Extras-Field-Reference" tabindex="-1">Extras Field Reference <a class="header-anchor" href="#Extras-Field-Reference" aria-label="Permalink to &quot;Extras Field Reference {#Extras-Field-Reference}&quot;">​</a></h2><p>PromptingTools populates <code>AIMessage.extras</code> with detailed metadata that Logfire.jl maps to OpenTelemetry GenAI semantic convention attributes. The fields use unified naming across providers for consistency.</p><h3 id="Provider-Metadata" tabindex="-1">Provider Metadata <a class="header-anchor" href="#Provider-Metadata" aria-label="Permalink to &quot;Provider Metadata {#Provider-Metadata}&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:right;">Extras Key</th><th style="text-align:right;">Type</th><th style="text-align:right;">Description</th><th style="text-align:right;">OpenAI</th><th style="text-align:right;">Anthropic</th></tr></thead><tbody><tr><td style="text-align:right;"><code>:model</code></td><td style="text-align:right;">String</td><td style="text-align:right;">Actual model used (may differ from requested)</td><td style="text-align:right;">✓</td><td style="text-align:right;">✓</td></tr><tr><td style="text-align:right;"><code>:response_id</code></td><td style="text-align:right;">String</td><td style="text-align:right;">Provider&#39;s unique response identifier</td><td style="text-align:right;">✓</td><td style="text-align:right;">✓</td></tr><tr><td style="text-align:right;"><code>:system_fingerprint</code></td><td style="text-align:right;">String</td><td style="text-align:right;">OpenAI system fingerprint for determinism</td><td style="text-align:right;">✓</td><td style="text-align:right;">-</td></tr><tr><td style="text-align:right;"><code>:service_tier</code></td><td style="text-align:right;">String</td><td style="text-align:right;">Service tier used (e.g., &quot;default&quot;, &quot;standard&quot;)</td><td style="text-align:right;">✓</td><td style="text-align:right;">✓</td></tr></tbody></table><h3 id="Unified-Usage-Keys" tabindex="-1">Unified Usage Keys <a class="header-anchor" href="#Unified-Usage-Keys" aria-label="Permalink to &quot;Unified Usage Keys {#Unified-Usage-Keys}&quot;">​</a></h3><p>These keys provide cross-provider compatibility. Use these for provider-agnostic code:</p><table tabindex="0"><thead><tr><th style="text-align:right;">Extras Key</th><th style="text-align:right;">Type</th><th style="text-align:right;">Description</th><th style="text-align:right;">OpenAI Source</th><th style="text-align:right;">Anthropic Source</th></tr></thead><tbody><tr><td style="text-align:right;"><code>:cache_read_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Tokens read from cache (cache hits)</td><td style="text-align:right;"><code>prompt_tokens_details.cached_tokens</code></td><td style="text-align:right;"><code>cache_read_input_tokens</code></td></tr><tr><td style="text-align:right;"><code>:cache_write_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Tokens written to cache</td><td style="text-align:right;">-</td><td style="text-align:right;"><code>cache_creation_input_tokens</code></td></tr><tr><td style="text-align:right;"><code>:reasoning_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Chain-of-thought/reasoning tokens</td><td style="text-align:right;"><code>completion_tokens_details.reasoning_tokens</code></td><td style="text-align:right;">-</td></tr><tr><td style="text-align:right;"><code>:audio_input_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Audio tokens in input</td><td style="text-align:right;"><code>prompt_tokens_details.audio_tokens</code></td><td style="text-align:right;">-</td></tr><tr><td style="text-align:right;"><code>:audio_output_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Audio tokens in output</td><td style="text-align:right;"><code>completion_tokens_details.audio_tokens</code></td><td style="text-align:right;">-</td></tr><tr><td style="text-align:right;"><code>:accepted_prediction_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Predicted tokens that were accepted</td><td style="text-align:right;"><code>completion_tokens_details.accepted_prediction_tokens</code></td><td style="text-align:right;">-</td></tr><tr><td style="text-align:right;"><code>:rejected_prediction_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Predicted tokens that were rejected</td><td style="text-align:right;"><code>completion_tokens_details.rejected_prediction_tokens</code></td><td style="text-align:right;">-</td></tr></tbody></table><h3 id="Anthropic-Specific-Keys" tabindex="-1">Anthropic-Specific Keys <a class="header-anchor" href="#Anthropic-Specific-Keys" aria-label="Permalink to &quot;Anthropic-Specific Keys {#Anthropic-Specific-Keys}&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:right;">Extras Key</th><th style="text-align:right;">Type</th><th style="text-align:right;">Description</th></tr></thead><tbody><tr><td style="text-align:right;"><code>:cache_write_1h_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Ephemeral 1-hour cache tokens</td></tr><tr><td style="text-align:right;"><code>:cache_write_5m_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Ephemeral 5-minute cache tokens</td></tr><tr><td style="text-align:right;"><code>:web_search_requests</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Server-side web search requests</td></tr><tr><td style="text-align:right;"><code>:cache_creation_input_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Original Anthropic key (backwards compat)</td></tr><tr><td style="text-align:right;"><code>:cache_read_input_tokens</code></td><td style="text-align:right;">Int</td><td style="text-align:right;">Original Anthropic key (backwards compat)</td></tr></tbody></table><h3 id="Raw-Provider-Dicts" tabindex="-1">Raw Provider Dicts <a class="header-anchor" href="#Raw-Provider-Dicts" aria-label="Permalink to &quot;Raw Provider Dicts {#Raw-Provider-Dicts}&quot;">​</a></h3><p>For debugging or advanced use cases, the original nested structures are preserved:</p><table tabindex="0"><thead><tr><th style="text-align:right;">Extras Key</th><th style="text-align:right;">Provider</th><th style="text-align:right;">Contents</th></tr></thead><tbody><tr><td style="text-align:right;"><code>:prompt_tokens_details</code></td><td style="text-align:right;">OpenAI</td><td style="text-align:right;"><code>{:cached_tokens, :audio_tokens}</code></td></tr><tr><td style="text-align:right;"><code>:completion_tokens_details</code></td><td style="text-align:right;">OpenAI</td><td style="text-align:right;"><code>{:reasoning_tokens, :audio_tokens, :accepted_prediction_tokens, :rejected_prediction_tokens}</code></td></tr><tr><td style="text-align:right;"><code>:cache_creation</code></td><td style="text-align:right;">Anthropic</td><td style="text-align:right;"><code>{:ephemeral_1h_input_tokens, :ephemeral_5m_input_tokens}</code></td></tr><tr><td style="text-align:right;"><code>:server_tool_use</code></td><td style="text-align:right;">Anthropic</td><td style="text-align:right;"><code>{:web_search_requests}</code></td></tr></tbody></table><h3 id="Example:-Accessing-Extras" tabindex="-1">Example: Accessing Extras <a class="header-anchor" href="#Example:-Accessing-Extras" aria-label="Permalink to &quot;Example: Accessing Extras {#Example:-Accessing-Extras}&quot;">​</a></h3><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What is 2+2?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt4om&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Provider metadata</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">println</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Model used: &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:model</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">println</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Response ID: &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:response_id</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Unified usage (works across providers)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">cache_hits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> get</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:cache_read_tokens</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">reasoning </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> get</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:reasoning_tokens</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Raw OpenAI details (if needed)</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> haskey</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:prompt_tokens_details</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    details </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">extras[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:prompt_tokens_details</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    println</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Cached: &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">get</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(details, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:cached_tokens</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><h2 id="Instrument-Individual-Models" tabindex="-1">Instrument Individual Models <a class="header-anchor" href="#Instrument-Individual-Models" aria-label="Permalink to &quot;Instrument Individual Models {#Instrument-Individual-Models}&quot;">​</a></h2><p>You don&#39;t have to instrument all models. For selective tracing, wrap only specific models:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">instrument_promptingtools_model!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;my-local-llm&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>This reuses the model&#39;s registered PromptingTools schema, so provider-specific behavior is preserved.</p><h2 id="Alternative-Backends" tabindex="-1">Alternative Backends <a class="header-anchor" href="#Alternative-Backends" aria-label="Permalink to &quot;Alternative Backends {#Alternative-Backends}&quot;">​</a></h2><p>You don&#39;t have to use Logfire cloud. Send traces to any OpenTelemetry-compatible backend using standard environment variables:</p><table tabindex="0"><thead><tr><th style="text-align:right;">Variable</th><th style="text-align:right;">Purpose</th></tr></thead><tbody><tr><td style="text-align:right;"><code>OTEL_EXPORTER_OTLP_ENDPOINT</code></td><td style="text-align:right;">Backend URL (e.g., <code>http://localhost:4318</code>)</td></tr><tr><td style="text-align:right;"><code>OTEL_EXPORTER_OTLP_HEADERS</code></td><td style="text-align:right;">Custom headers (e.g., <code>Authorization=Bearer token</code>)</td></tr></tbody></table><h3 id="Local-Development-with-Jaeger" tabindex="-1">Local Development with Jaeger <a class="header-anchor" href="#Local-Development-with-Jaeger" aria-label="Permalink to &quot;Local Development with Jaeger {#Local-Development-with-Jaeger}&quot;">​</a></h3><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Start Jaeger</span></span>\n<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --rm</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 16686:16686</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 4318:4318</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> jaegertracing/all-in-one:latest</span></span></code></pre></div><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Logfire</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ENV</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;OTEL_EXPORTER_OTLP_ENDPOINT&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;http://localhost:4318&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">configure</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    service_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;my-app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    send_to_logfire </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> :always</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # Export even without Logfire token</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">instrument_promptingtools!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Now use PromptingTools normally - traces go to Jaeger</span></span></code></pre></div><p>View traces at: <a href="http://localhost:16686" target="_blank" rel="noreferrer">http://localhost:16686</a></p><h3 id="Using-with-Langfuse" tabindex="-1">Using with Langfuse <a class="header-anchor" href="#Using-with-Langfuse" aria-label="Permalink to &quot;Using with Langfuse {#Using-with-Langfuse}&quot;">​</a></h3><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ENV</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;OTEL_EXPORTER_OTLP_ENDPOINT&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://cloud.langfuse.com/api/public/otel&quot;</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ENV</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;OTEL_EXPORTER_OTLP_HEADERS&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Authorization=Basic &lt;base64-credentials&gt;&quot;</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">configure</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(service_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;my-llm-app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, send_to_logfire </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> :always</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="Recommended:-Pydantic-Logfire" tabindex="-1">Recommended: Pydantic Logfire <a class="header-anchor" href="#Recommended:-Pydantic-Logfire" aria-label="Permalink to &quot;Recommended: Pydantic Logfire {#Recommended:-Pydantic-Logfire}&quot;">​</a></h2><p>While you can use any OTLP-compatible backend, we strongly recommend <a href="https://pydantic.dev/logfire" target="_blank" rel="noreferrer">Pydantic Logfire</a>. Their free tier provides hundreds of thousands of traced conversations per month, which is more than enough for most use cases. The UI is purpose-built for LLM observability with excellent visualization of conversations, token usage, and costs.</p><h2 id="Authentication" tabindex="-1">Authentication <a class="header-anchor" href="#Authentication" aria-label="Permalink to &quot;Authentication {#Authentication}&quot;">​</a></h2><ul><li><p>Provide your Logfire token via <code>Logfire.configure(token = &quot;...&quot;)</code> or set <code>ENV[&quot;LOGFIRE_TOKEN&quot;]</code></p></li><li><p>Use <code>DotEnv.load!()</code> to load tokens from a project-local <code>.env</code> file (recommended for per-project configuration)</p></li></ul><h2 id="Example" tabindex="-1">Example <a class="header-anchor" href="#Example" aria-label="Permalink to &quot;Example {#Example}&quot;">​</a></h2><p>See the full example at <a href="https://github.com/svilupp/PromptingTools.jl/blob/main/examples/observability_with_logfire.jl" target="_blank" rel="noreferrer"><code>examples/observability_with_logfire.jl</code></a>.</p><h2 id="Combining-with-TextPrompts.jl" tabindex="-1">Combining with TextPrompts.jl <a class="header-anchor" href="#Combining-with-TextPrompts.jl" aria-label="Permalink to &quot;Combining with TextPrompts.jl {#Combining-with-TextPrompts.jl}&quot;">​</a></h2><p>For a complete LLM workflow, combine Logfire.jl with <a href="./extra_tools/prompt_management_textprompts">TextPrompts.jl</a> for prompt management:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TextPrompts, PromptingTools, Logfire</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">configure</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(service_name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;my-app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Logfire</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">instrument_promptingtools!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Load prompts from version-controlled files</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">system </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> load_prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;prompts/system.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)(; role </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Expert&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SystemMessage</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">user </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> load_prompt</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;prompts/task.txt&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)(; task </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;analyze data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> UserMessage</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Traces include full conversation with formatted prompts</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([system, user]; model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt4om&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>This enables a powerful workflow: version prompts in git, trace calls in Logfire, and continuously improve based on real-world performance.</p><h2 id="Further-Reading" tabindex="-1">Further Reading <a class="header-anchor" href="#Further-Reading" aria-label="Permalink to &quot;Further Reading {#Further-Reading}&quot;">​</a></h2><ul><li><p><a href="https://svilupp.github.io/Logfire.jl/dev" target="_blank" rel="noreferrer">Logfire.jl Documentation</a></p></li><li><p><a href="https://github.com/svilupp/Logfire.jl" target="_blank" rel="noreferrer">Logfire.jl GitHub</a></p></li><li><p><a href="https://pydantic.dev/logfire" target="_blank" rel="noreferrer">Pydantic Logfire</a></p></li><li><p><a href="./extra_tools/prompt_management_textprompts">TextPrompts.jl - Prompt Management</a></p></li><li><p><a href="https://discourse.julialang.org/t/announcing-logfire-jl-textprompts-jl-observability-and-prompt-management-for-julia-genai/134268" target="_blank" rel="noreferrer">Discourse Announcement</a></p></li></ul>', 59)
  ])]);
}
const observability_logfire = /* @__PURE__ */ _export_sfc(_sfc_main, [["render", _sfc_render]]);
export {
  __pageData,
  observability_logfire as default
};
