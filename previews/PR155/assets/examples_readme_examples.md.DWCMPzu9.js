import { _ as _export_sfc, c as createElementBlock, m as createBaseVNode, a as createTextVNode, t as toDisplayString, a7 as createStaticVNode, o as openBlock } from "./chunks/framework.DOQH_xZA.js";
const __pageData = JSON.parse('{"title":"Various Examples","description":"","frontmatter":{},"headers":[],"relativePath":"examples/readme_examples.md","filePath":"examples/readme_examples.md","lastUpdated":null}');
const _sfc_main = { name: "examples/readme_examples.md" };
const _hoisted_1 = /* @__PURE__ */ createStaticVNode('<h1 id="Various-Examples" tabindex="-1">Various Examples <a class="header-anchor" href="#Various-Examples" aria-label="Permalink to &quot;Various Examples {#Various-Examples}&quot;">​</a></h1><h2 id="ai*-Functions-Overview" tabindex="-1"><code>ai*</code> Functions Overview <a class="header-anchor" href="#ai*-Functions-Overview" aria-label="Permalink to &quot;`ai*` Functions Overview {#ai*-Functions-Overview}&quot;">​</a></h2><p>Noteworthy functions: <code>aigenerate</code>, <code>aiembed</code>, <code>aiclassify</code>, <code>aiextract</code>, <code>aiscan</code>, <code>aiimage</code>, <code>aitemplates</code></p><p>All <code>ai*</code> functions have the same basic structure:</p><p><code>ai*(&lt;optional schema&gt;,&lt;prompt or conversation&gt;; &lt;optional keyword arguments&gt;)</code>,</p><p>but they differ in purpose:</p><ul><li><p><code>aigenerate</code> is the general-purpose function to generate any text response with LLMs, ie, it returns <code>AIMessage</code> with field <code>:content</code> containing the generated text (eg, <code>ans.content isa AbstractString</code>)</p></li><li><p><code>aiembed</code> is designed to extract embeddings from the AI model&#39;s response, ie, it returns <code>DataMessage</code> with field <code>:content</code> containing the embeddings (eg, <code>ans.content isa AbstractArray</code>)</p></li><li><p><code>aiextract</code> is designed to extract structured data from the AI model&#39;s response and return them as a Julia struct (eg, if we provide <code>return_type=Food</code>, we get <code>ans.content isa Food</code>). You need to define the return type first and then provide it as a keyword argument.</p></li><li><p><code>aiclassify</code> is designed to classify the input text into (or simply respond within) a set of discrete <code>choices</code> provided by the user. It can be very useful as an LLM Judge or a router for RAG systems, as it uses the &quot;logit bias trick&quot; and generates exactly 1 token. It returns <code>AIMessage</code> with field <code>:content</code>, but the <code>:content</code> can be only one of the provided <code>choices</code> (eg, <code>ans.content in choices</code>)</p></li><li><p><code>aiscan</code> is for working with images and vision-enabled models (as an input), but it returns <code>AIMessage</code> with field <code>:content</code> containing the generated text (eg, <code>ans.content isa AbstractString</code>) similar to <code>aigenerate</code>.</p></li><li><p><code>aiimage</code> is for generating images (eg, with OpenAI DALL-E 3). It returns a <code>DataMessage</code>, where the field <code>:content</code> might contain either the URL to download the image from or the Base64-encoded image depending on the user-provided kwarg <code>api_kwargs.response_format</code>.</p></li><li><p><code>aitemplates</code> is a helper function to discover available templates and see their details (eg, <code>aitemplates(&quot;some keyword&quot;)</code> or <code>aitemplates(:AssistantAsk)</code>)</p></li></ul><p>If you&#39;re using a known <code>model</code>, you do NOT need to provide a <code>schema</code> (the first argument).</p><p>Optional keyword arguments in <code>ai*</code> tend to be:</p><ul><li><p><code>model::String</code> - Which model you want to use</p></li><li><p><code>verbose::Bool</code> - Whether you went to see INFO logs around AI costs</p></li><li><p><code>return_all::Bool</code> - Whether you want the WHOLE conversation or just the AI answer (ie, whether you want to include your inputs/prompt in the output)</p></li><li><p><code>api_kwargs::NamedTuple</code> - Specific parameters for the model, eg, <code>temperature=0.0</code> to be NOT creative (and have more similar output in each run)</p></li><li><p><code>http_kwargs::NamedTuple</code> - Parameters for the HTTP.jl package, eg, <code>readtimeout = 120</code> to time out in 120 seconds if no response was received.</p></li></ul><p><strong>Experimental: AgentTools</strong></p><p>In addition to the above list of <code>ai*</code> functions, you can also use the <strong>&quot;lazy&quot; counterparts</strong> of these functions from the experimental AgentTools module.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Experimental</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">AgentTools</span></span></code></pre></div><p>For example, <code>AIGenerate()</code> will create a lazy instance of <code>aigenerate</code>. It is an instance of <code>AICall</code> with <code>aigenerate</code> as its ai function. It uses exactly the same arguments and keyword arguments as <code>aigenerate</code> (see <code>?aigenerate</code> for details).</p><p>&quot;lazy&quot; refers to the fact that it does NOT generate any output when instantiated (only when <code>run!</code> is called).</p><p>Or said differently, the <code>AICall</code> struct and all its flavors (<code>AIGenerate</code>, ...) are designed to facilitate a deferred execution model (lazy evaluation) for AI functions that interact with a Language Learning Model (LLM). It stores the necessary information for an AI call and executes the underlying AI function only when supplied with a <code>UserMessage</code> or when the <code>run!</code> method is applied. This allows us to remember user inputs and trigger the LLM call repeatedly if needed, which enables automatic fixing (see <code>?airetry!</code>).</p><p><strong>Experimental: RAGTools</strong></p><p>Lastly, we provide a set of tools to build RAG applications (Retrieve, Answer, Generate).</p><p>It can be as simple as two calls: <code>build_index</code> and <code>airag</code> (Retrieve, Answer, Generate).</p><p>If you then use pretty-printing with <code>PromptingTools.pprint</code>, we highlight the generated text vs text likely sourced from the context and we score how strongly is the generated answer supported by the context. In addition, we annotate each generated chunk with a reference to which source document it likely came from (including the confidence score between 0 and 1).</p><h2 id="Seamless-Integration-Into-Your-Workflow" tabindex="-1">Seamless Integration Into Your Workflow <a class="header-anchor" href="#Seamless-Integration-Into-Your-Workflow" aria-label="Permalink to &quot;Seamless Integration Into Your Workflow {#Seamless-Integration-Into-Your-Workflow}&quot;">​</a></h2><p>Google search is great, but it&#39;s a context switch. You often have to open a few pages and read through the discussion to find the answer you need. Same with the ChatGPT website.</p><p>Imagine you are in VSCode, editing your <code>.gitignore</code> file. How do I ignore a file in all subfolders again?</p><p>All you need to do is to type: <code>aai&quot;What to write in .gitignore to ignore file XYZ in any folder or subfolder?&quot;</code></p><p>With <code>aai&quot;&quot;</code> (as opposed to <code>ai&quot;&quot;</code>), we make a non-blocking call to the LLM to not prevent you from continuing your work. When the answer is ready, we log it from the background:</p><div class="language-plaintext vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>[ Info: Tokens: 102 @ Cost: $0.0002 in 2.7 seconds</span></span>\n<span class="line"><span>┌ Info: AIMessage&gt; To ignore a file called &quot;XYZ&quot; in any folder or subfolder, you can add the following line to your .gitignore file:</span></span>\n<span class="line"><span>│ </span></span>\n<span class="line"><span>│ ```</span></span>\n<span class="line"><span>│ **/XYZ</span></span>\n<span class="line"><span>│ ```</span></span>\n<span class="line"><span>│ </span></span>\n<span class="line"><span>└ This pattern uses the double asterisk (`**`) to match any folder or subfolder, and then specifies the name of the file you want to ignore.</span></span></code></pre></div><p>You probably saved 3-5 minutes on this task and probably another 5-10 minutes, because of the context switch/distraction you avoided. It&#39;s a small win, but it adds up quickly.</p><h2 id="Advanced-Prompts-/-Conversations" tabindex="-1">Advanced Prompts / Conversations <a class="header-anchor" href="#Advanced-Prompts-/-Conversations" aria-label="Permalink to &quot;Advanced Prompts / Conversations {#Advanced-Prompts-/-Conversations}&quot;">​</a></h2>', 28);
const _hoisted_29 = /* @__PURE__ */ createBaseVNode("code", null, "aigenerate", -1);
const _hoisted_30 = /* @__PURE__ */ createStaticVNode('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Say hello to {{name}}!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;World&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>The more complex prompts are effectively a conversation (a set of messages), where you can have messages from three entities: System, User, AI Assistant. We provide the corresponding types for each of them: <code>SystemMessage</code>, <code>UserMessage</code>, <code>AIMessage</code>.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SystemMessage, UserMessage</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">conversation </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    SystemMessage</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;You&#39;re master Yoda from Star Wars trying to help the user become a Jedi.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    UserMessage</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;I have feelings for my {{object}}. What should I do?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)]</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(conversation; object </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;old iPhone&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language-plaintext vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>AIMessage(&quot;Ah, a dilemma, you have. Emotional attachment can cloud your path to becoming a Jedi. To be attached to material possessions, you must not. The iPhone is but a tool, nothing more. Let go, you must.</span></span>\n<span class="line"><span></span></span>\n<span class="line"><span>Seek detachment, young padawan. Reflect upon the impermanence of all things. Appreciate the memories it gave you, and gratefully part ways. In its absence, find new experiences to grow and become one with the Force. Only then, a true Jedi, you shall become.&quot;)</span></span></code></pre></div><p>You can also use it to build conversations, eg,</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">new_conversation </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> vcat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(conversation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,msg, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">UserMessage</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Thank you, master Yoda! Do you have {{object}} to know what it feels like?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(new_conversation; object </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;old iPhone&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><div class="language-plaintext vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>&gt; AIMessage(&quot;Hmm, possess an old iPhone, I do not. But experience with attachments, I have. Detachment, I learned. True power and freedom, it brings...&quot;)</span></span></code></pre></div><h2 id="Templated-Prompts" tabindex="-1">Templated Prompts <a class="header-anchor" href="#Templated-Prompts" aria-label="Permalink to &quot;Templated Prompts {#Templated-Prompts}&quot;">​</a></h2><p>With LLMs, the quality / robustness of your results depends on the quality of your prompts. But writing prompts is hard! That&#39;s why we offer a templating system to save you time and effort.</p><p>To use a specific template (eg, `` to ask a Julia language):</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:JuliaExpertAsk</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; ask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;How do I add packages?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>The above is equivalent to a more verbose version that explicitly uses the dispatch on <code>AITemplate</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AITemplate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:JuliaExpertAsk</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">); ask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;How do I add packages?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Find available templates with <code>aitemplates</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tmps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aitemplates</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;JuliaExpertAsk&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Will surface one specific template</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1-element Vector{AITemplateMetadata}:</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># PromptingTools.AITemplateMetadata</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   name: Symbol JuliaExpertAsk</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   description: String &quot;For asking questions about Julia language. Placeholders: `ask`&quot;</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   version: String &quot;1&quot;</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   wordcount: Int64 237</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   variables: Array{Symbol}((1,))</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   system_preview: String &quot;You are a world-class Julia language programmer with the knowledge of the latest syntax. Your commun&quot;</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   user_preview: String &quot;# Question\\n\\n{{ask}}&quot;</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#   source: String &quot;&quot;</span></span></code></pre></div><p>The above gives you a good idea of what the template is about, what placeholders are available, and how much it would cost to use it (=wordcount).</p><p>Search for all Julia-related templates:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tmps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aitemplates</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Julia&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2-element Vector{AITemplateMetadata}... -&gt; more to come later!</span></span></code></pre></div><p>If you are on VSCode, you can leverage a nice tabular display with <code>vscodedisplay</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DataFrames</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tmps </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aitemplates</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Julia&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DataFrame </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> vscodedisplay</span></span></code></pre></div><p>I have my selected template, how do I use it? Just use the &quot;name&quot; in <code>aigenerate</code> or <code>aiclassify</code> like you see in the first example!</p><p>You can inspect any template by &quot;rendering&quot; it (this is what the LLM will see):</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">julia</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AITemplate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:JudgeIsItTrue</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">render</span></span></code></pre></div><p>See more examples in the <a href="https://github.com/svilupp/PromptingTools.jl/tree/main/examples" target="_blank" rel="noreferrer">Examples</a> folder.</p><h2 id="Asynchronous-Execution" tabindex="-1">Asynchronous Execution <a class="header-anchor" href="#Asynchronous-Execution" aria-label="Permalink to &quot;Asynchronous Execution {#Asynchronous-Execution}&quot;">​</a></h2><p>You can leverage <code>asyncmap</code> to run multiple AI-powered tasks concurrently, improving performance for batch operations.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Translate &#39;Hello, World!&#39; to {{language}}&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; language) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> language </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Spanish&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;French&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Mandarin&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">responses </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> asyncmap</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(aigenerate, prompts)</span></span></code></pre></div><p>Pro tip: You can limit the number of concurrent tasks with the keyword <code>asyncmap(...; ntasks=10)</code>.</p><h2 id="Model-Aliases" tabindex="-1">Model Aliases <a class="header-anchor" href="#Model-Aliases" aria-label="Permalink to &quot;Model Aliases {#Model-Aliases}&quot;">​</a></h2><p>Certain tasks require more powerful models. All user-facing functions have a keyword argument <code>model</code> that can be used to specify the model to be used. For example, you can use <code>model = &quot;gpt-4-1106-preview&quot;</code> to use the latest GPT-4 Turbo model. However, no one wants to type that!</p><p>We offer a set of model aliases (eg, &quot;gpt3&quot;, &quot;gpt4&quot;, &quot;gpt4t&quot; -&gt; the above GPT-4 Turbo, etc.) that can be used instead.</p><p>Each <code>ai...</code> call first looks up the provided model name in the dictionary <code>PromptingTools.MODEL_ALIASES</code>, so you can easily extend with your own aliases!</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PT </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PT</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MODEL_ALIASES[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt4t&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt-4-1106-preview&quot;</span></span></code></pre></div><p>These aliases also can be used as flags in the <code>@ai_str</code> macro, eg, <code>ai&quot;What is the capital of France?&quot;gpt4t</code> (GPT-4 Turbo has a knowledge cut-off in April 2023, so it&#39;s useful for more contemporary questions).</p><h2 id="Embeddings" tabindex="-1">Embeddings <a class="header-anchor" href="#Embeddings" aria-label="Permalink to &quot;Embeddings {#Embeddings}&quot;">​</a></h2><p>Use the <code>aiembed</code> function to create embeddings via the default OpenAI model that can be used for semantic search, clustering, and more complex AI workflows.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">text_to_embed </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;The concept of artificial intelligence.&quot;</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiembed</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text_to_embed)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embedding </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1536-element Vector{Float64}</span></span></code></pre></div><p>If you plan to calculate the cosine distance between embeddings, you can normalize them first:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LinearAlgebra</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiembed</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;embed me&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;and me too&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], LinearAlgebra</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">normalize)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># calculate cosine distance between the two normalized embeddings as a simple dot product</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [1.0, 0.787]</span></span></code></pre></div><h2 id="Classification" tabindex="-1">Classification <a class="header-anchor" href="#Classification" aria-label="Permalink to &quot;Classification {#Classification}&quot;">​</a></h2><p>You can use the <code>aiclassify</code> function to classify any provided statement as true/false/unknown. This is useful for fact-checking, hallucination or NLI checks, moderation, filtering, sentiment analysis, feature engineering and more.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aiclassify</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Is two plus two four?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span></code></pre></div><p>System prompts and higher-quality models can be used for more complex tasks, including knowing when to defer to a human:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aiclassify</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:JudgeIsItTrue</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; it </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Is two plus three a vegetable on Mars?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;gpt4t&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># unknown</span></span></code></pre></div><p>In the above example, we used a prompt template <code>:JudgeIsItTrue</code>, which automatically expands into the following system prompt (and a separate user prompt):</p><blockquote><p>&quot;You are an impartial AI judge evaluating whether the provided statement is &quot;true&quot; or &quot;false&quot;. Answer &quot;unknown&quot; if you cannot decide.&quot;</p></blockquote><p>For more information on templates, see the <a href="/PromptingTools.jl/previews/PR155/examples/readme_examples#templated-prompts">Templated Prompts</a> section.</p><h3 id="Routing-to-Defined-Categories" tabindex="-1">Routing to Defined Categories <a class="header-anchor" href="#Routing-to-Defined-Categories" aria-label="Permalink to &quot;Routing to Defined Categories {#Routing-to-Defined-Categories}&quot;">​</a></h3><p><code>aiclassify</code> can be also used for classification into a set of defined categories (maximum 20), so we can use it for routing.</p><p>In addition, if you provide the choices as tuples (<code>(label, description)</code>), the model will use the descriptions to decide, but it will return the labels.</p><p>Example:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">choices </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;A&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;any animal or creature&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;P&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;for any plant or tree&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), (</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;O&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;for everything else&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)]</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;spider&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aiclassify</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:InputClassifier</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; choices, input) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># -&gt; returns &quot;A&quot; for any animal or creature</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Try also with:</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;daphodil&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # -&gt; returns &quot;P&quot; for any plant or tree</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;castle&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # -&gt; returns &quot;O&quot; for everything else</span></span></code></pre></div><p>Under the hood, we use the &quot;logit bias&quot; trick to force only 1 generated token - that means it&#39;s very cheap and very fast!</p><h2 id="Data-Extraction" tabindex="-1">Data Extraction <a class="header-anchor" href="#Data-Extraction" aria-label="Permalink to &quot;Data Extraction {#Data-Extraction}&quot;">​</a></h2><p>Are you tired of extracting data with regex? You can use LLMs to extract structured data from text!</p><p>All you have to do is to define the structure of the data you want to extract and the LLM will do the rest.</p><p>Define a <code>return_type</code> with struct. Provide docstrings if needed (improves results and helps with documentation).</p><p>Let&#39;s start with a hard task - extracting the current weather in a given location:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">@enum</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TemperatureUnits celsius fahrenheit</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;Extract the current weather in a given location</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"># Arguments</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">- `location`: The city and state, e.g. &quot;San Francisco, CA&quot;</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">- `unit`: The unit of temperature to return, either `celsius` or `fahrenheit`</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;&quot;</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> CurrentWeather</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    location</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">String</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    unit</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Union{Nothing,TemperatureUnits}</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note that we provide the TYPE itself, not an instance of it!</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiextract</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;What&#39;s the weather in Salt Lake City in C?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; return_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">CurrentWeather)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># CurrentWeather(&quot;Salt Lake City, UT&quot;, celsius)</span></span></code></pre></div><p>But you can use it even for more complex tasks, like extracting many entities from a text:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Person&#39;s age, height, and weight.&quot;</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyMeasurement</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    age</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Int</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    height</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Union{Int,Nothing}</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    weight</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Union{Nothing,Float64}</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">struct</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ManyMeasurements</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    measurements</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Vector{MyMeasurement}</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiextract</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;James is 30, weighs 80kg. He&#39;s 180cm tall. Then Jack is 19 but really tall - over 190!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; return_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ManyMeasurements)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">measurements</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2-element Vector{MyMeasurement}:</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#  MyMeasurement(30, 180, 80.0)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#  MyMeasurement(19, 190, nothing)</span></span></code></pre></div><p>There is even a wrapper to help you catch errors together with helpful explanations on why parsing failed. See <code>?PromptingTools.MaybeExtract</code> for more information.</p><h2 id="OCR-and-Image-Comprehension" tabindex="-1">OCR and Image Comprehension <a class="header-anchor" href="#OCR-and-Image-Comprehension" aria-label="Permalink to &quot;OCR and Image Comprehension {#OCR-and-Image-Comprehension}&quot;">​</a></h2><p>With the <code>aiscan</code> function, you can interact with images as if they were text.</p><p>You can simply describe a provided image:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiscan</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Describe the image&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; image_path</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;julia.png&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt4v&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [ Info: Tokens: 1141 @ Cost: \\$0.0117 in 2.2 seconds</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># AIMessage(&quot;The image shows a logo consisting of the word &quot;julia&quot; written in lowercase&quot;)</span></span></code></pre></div><p>Or you can do an OCR of a screenshot. Let&#39;s transcribe some SQL code from a screenshot (no more re-typing!), we use a template <code>:OCRTask</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Screenshot of some SQL code</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">image_url </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://www.sqlservercentral.com/wp-content/uploads/legacy/8755f69180b7ac7ee76a69ae68ec36872a116ad4/24622.png&quot;</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiscan</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:OCRTask</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; image_url, model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt4v&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, task</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Transcribe the SQL code in the image.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, api_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [ Info: Tokens: 362 @ Cost: \\$0.0045 in 2.5 seconds</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># AIMessage(&quot;```sql</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># update Orders &lt;continue&gt;</span></span></code></pre></div><p>You can add syntax highlighting of the outputs via Markdown</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Markdown</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Markdown</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">parse</span></span></code></pre></div><h2 id="Experimental-Agent-Workflows-/-Output-Validation-with-airetry!" tabindex="-1">Experimental Agent Workflows / Output Validation with <code>airetry!</code> <a class="header-anchor" href="#Experimental-Agent-Workflows-/-Output-Validation-with-airetry!" aria-label="Permalink to &quot;Experimental Agent Workflows / Output Validation with `airetry!` {#Experimental-Agent-Workflows-/-Output-Validation-with-airetry!}&quot;">​</a></h2><p>This is an experimental feature, so you have to import it explicitly:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Experimental</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">AgentTools</span></span></code></pre></div><p>This module offers &quot;lazy&quot; counterparts to the <code>ai...</code> functions, so you can use them in a more controlled way, eg, <code>aigenerate</code> -&gt; <code>AIGenerate</code> (notice the CamelCase), which has exactly the same arguments except it generates only when <code>run!</code> is called.</p><p>For example:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AIGenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Say hi!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt4t&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">run!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out)</span></span></code></pre></div><p>How is it useful? We can use the same &quot;inputs&quot; for repeated calls, eg, when we want to validate or regenerate some outputs. We have a function <code>airetry</code> to help us with that.</p><p>The signature of <code>airetry</code> is <code>airetry(condition_function, aicall::AICall, feedback_function)</code>. It evaluates the condition <code>condition_function</code> on the <code>aicall</code> object (eg, we evaluate <code>f_cond(aicall) -&gt; Bool</code>). If it fails, we call <code>feedback_function</code> on the <code>aicall</code> object to provide feedback for the AI model (eg, <code>f_feedback(aicall) -&gt; String</code>) and repeat the process until it passes or until <code>max_retries</code> value is exceeded.</p><p>We can catch API failures (no feedback needed, so none is provided)</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># API failure because of a non-existent model</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># RetryConfig allows us to change the &quot;retry&quot; behaviour of any lazy call</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AIGenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;say hi!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> RetryConfig</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; catch_errors </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;NOTEXIST&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">run!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># fails</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># we ask to wait 2s between retries and retry 2 times (can be set in `config` in aicall as well)</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">airetry!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(isvalid, out; retry_delay </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, max_retries </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Or we can validate some outputs (eg, its format, its content, etc.)</p><p>We&#39;ll play a color guessing game (I&#39;m thinking &quot;yellow&quot;):</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Notice that we ask for two samples (`n_samples=2`) at each attempt (to improve our chances). </span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Both guesses are scored at each time step, and the best one is chosen for the next step.</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># And with OpenAI, we can set `api_kwargs = (;n=2)` to get both samples simultaneously (cheaper and faster)!</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">out </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AIGenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Guess what color I&#39;m thinking. It could be: blue, red, black, white, yellow. Answer with 1 word only&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    verbose </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> RetryConfig</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; n_samples </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), api_kwargs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (; n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">run!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">## Check that the output is 1 word only, third argument is the feedback that will be provided if the condition fails</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">## Notice: functions operate on `aicall` as the only argument. We can use utilities like `last_output` and `last_message` to access the last message and output in the conversation.</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">airetry!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> length</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">split</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">last_output</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">r&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;"> |</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;--shiki-light-font-weight:bold;--shiki-dark-font-weight:bold;">\\\\</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, out,</span></span>\n<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;You must answer with 1 word only.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note: you could also use the do-syntax, eg, </span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">airetry!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(out, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;You must answer with 1 word only.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">do</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> aicall</span></span>\n<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    length</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">split</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">last_output</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(aicall), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">r&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;"> |</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;--shiki-light-font-weight:bold;--shiki-dark-font-weight:bold;">\\\\</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;">.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span></span>\n<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">end</span></span></code></pre></div><p>You can place multiple <code>airetry!</code> calls in a sequence. They will keep retrying until they run out of maximum AI calls allowed (<code>max_calls</code>) or maximum retries (<code>max_retries</code>).</p><p>See the docs for more complex examples and usage tips (<code>?airetry</code>). We leverage Monte Carlo Tree Search (MCTS) to optimize the sequence of retries, so it&#39;s a very powerful tool for building robust AI workflows (inspired by <a href="https://arxiv.org/abs/2310.04406" target="_blank" rel="noreferrer">Language Agent Tree Search paper</a> and by <a href="https://arxiv.org/abs/2312.13382" target="_blank" rel="noreferrer">DSPy Assertions paper</a>).</p><h2 id="Using-Ollama-models" tabindex="-1">Using Ollama models <a class="header-anchor" href="#Using-Ollama-models" aria-label="Permalink to &quot;Using Ollama models {#Using-Ollama-models}&quot;">​</a></h2><p><a href="https://ollama.ai/" target="_blank" rel="noreferrer">Ollama.ai</a> is an amazingly simple tool that allows you to run several Large Language Models (LLM) on your computer. It&#39;s especially suitable when you&#39;re working with some sensitive data that should not be sent anywhere.</p><p>Let&#39;s assume you have installed Ollama, downloaded a model, and it&#39;s running in the background.</p><p>We can use it with the <code>aigenerate</code> function:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PT </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">schema </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PT</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">OllamaManagedSchema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># notice the different schema!</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(schema, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Say hi!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;openhermes2.5-mistral&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [ Info: Tokens: 69 in 0.9 seconds</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># AIMessage(&quot;Hello! How can I assist you today?&quot;)</span></span></code></pre></div><p>And we can also use the <code>aiembed</code> function:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiembed</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(schema, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Embed me&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, copy; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;openhermes2.5-mistral&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4096-element JSON3.Array{Float64...</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aiembed</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(schema, [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Embed me&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Embed me&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;openhermes2.5-mistral&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">content </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 4096×2 Matrix{Float64}:</span></span></code></pre></div><p>If you&#39;re getting errors, check that Ollama is running - see the <a href="/PromptingTools.jl/previews/PR155/examples/readme_examples#setup-guide-for-ollama">Setup Guide for Ollama</a> section below.</p><h2 id="Using-MistralAI-API-and-other-OpenAI-compatible-APIs" tabindex="-1">Using MistralAI API and other OpenAI-compatible APIs <a class="header-anchor" href="#Using-MistralAI-API-and-other-OpenAI-compatible-APIs" aria-label="Permalink to &quot;Using MistralAI API and other OpenAI-compatible APIs {#Using-MistralAI-API-and-other-OpenAI-compatible-APIs}&quot;">​</a></h2><p>Mistral models have long been dominating the open-source space. They are now available via their API, so you can use them with PromptingTools.jl!</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Say hi!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mistral-tiny&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [ Info: Tokens: 114 @ Cost: $0.0 in 0.9 seconds</span></span>\n<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># AIMessage(&quot;Hello there! I&#39;m here to help answer any questions you might have, or assist you with tasks to the best of my abilities. How can I be of service to you today? If you have a specific question, feel free to ask and I&#39;ll do my best to provide accurate and helpful information. If you&#39;re looking for general assistance, I can help you find resources or information on a variety of topics. Let me know how I can help.&quot;)</span></span></code></pre></div><p>It all just works, because we have registered the models in the <code>PromptingTools.MODEL_REGISTRY</code>! There are currently 4 models available: <code>mistral-tiny</code>, <code>mistral-small</code>, <code>mistral-medium</code>, <code>mistral-embed</code>.</p><p>Under the hood, we use a dedicated schema <code>MistralOpenAISchema</code> that leverages most of the OpenAI-specific code base, so you can always provide that explicitly as the first argument:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PT </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(PT</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MistralOpenAISchema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Say Hi!&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mistral-tiny&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">ENV</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;MISTRALAI_API_KEY&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre></div><p>As you can see, we can load your API key either from the ENV or via the Preferences.jl mechanism (see <code>?PREFERENCES</code> for more information).</p><p>But MistralAI are not the only ones! There are many other exciting providers, eg, <a href="https://docs.perplexity.ai/" target="_blank" rel="noreferrer">Perplexity.ai</a>, <a href="https://app.fireworks.ai/" target="_blank" rel="noreferrer">Fireworks.ai</a>. As long as they are compatible with the OpenAI API (eg, sending <code>messages</code> with <code>role</code> and <code>content</code> keys), you can use them with PromptingTools.jl by using <code>schema = CustomOpenAISchema()</code>:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Set your API key and the necessary base URL for the API</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">api_key </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;...&quot;</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Say hi!&quot;</span></span>\n<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">msg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> aigenerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(PT</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">CustomOpenAISchema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(), prompt; model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;my_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, api_key, api_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;http://localhost:8081&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span></code></pre></div><p>As you can see, it also works for any local models that you might have running on your computer!</p><p>Note: At the moment, we only support <code>aigenerate</code> and <code>aiembed</code> functions for MistralAI and other OpenAI-compatible APIs. We plan to extend the support in the future.</p>', 104);
function _sfc_render(_ctx, _cache, $props, $setup, $data, $options) {
  return openBlock(), createElementBlock("div", null, [
    _hoisted_1,
    createBaseVNode("p", null, [
      createTextVNode("You can use the "),
      _hoisted_29,
      createTextVNode(" function to replace handlebar variables (eg, "),
      createBaseVNode("code", null, toDisplayString(_ctx.name), 1),
      createTextVNode(") via keyword arguments.")
    ]),
    _hoisted_30
  ]);
}
const readme_examples = /* @__PURE__ */ _export_sfc(_sfc_main, [["render", _sfc_render]]);
export {
  __pageData,
  readme_examples as default
};
